{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jBP6Bbq5wvG"
      },
      "source": [
        "# Machine Learning Spam Classification using Transformers\n",
        "\n",
        "Author: Bryan Lau\n",
        "\n",
        "## Overview  \n",
        "\n",
        "An application of machine learning for the classification of spam emails, using the popular Transformer model as outlined in Google's paper [Attention Is All You Need](https://doi.org/10.48550/arXiv.1706.03762) (Vaswan, et al., 2017).\n",
        "\n",
        "Transformer models incorporate a mechanism described in the Google paper as Multi-Head Attention, that lets the model discover relationships between words throughout the text, without suffering from the short-term memory limitations that recurrent models such as RNN or LSTM models do (Vaswani, et al., 2017).  \n",
        "\n",
        "Transformers are popularly used in a generative manner (e.g. ChatGPT), but I'll be using the model in a discriminative fashion here.\n",
        "\n",
        "## Dataset  \n",
        "I used the [Email Spam](https://www.kaggle.com/datasets/veleon/ham-and-spam-dataset) dataset from Kaggle, which contains about 3000 ham (legitimate) and spam emails. The data was split into training, validation and test sets.  \n",
        "\n",
        "## Evaluation  \n",
        "The performance of the model was evaluated based on its predictive accuracy against the test data, using common statistical metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB-32pSY5wvH"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wib0j7JT5wvH"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import time\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shsE1hLN5wvH"
      },
      "source": [
        "## Definitions\n",
        "\n",
        "Some global definitions that I used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "llhI5Rh95wvH"
      },
      "outputs": [],
      "source": [
        "# The base directory containing the ham/spam emails\n",
        "BASE_EMAILS_DIR = \"./emails\"\n",
        "\n",
        "# The maximum permitted word length, based on the longest English \n",
        "# words likely to be encountered in general text (Eckler, 1996)\n",
        "MAX_WORD_LEN = 22\n",
        "\n",
        "# The ratio to split training/validation/test data\n",
        "# This analysis will use a 70/15/15 split\n",
        "TRAIN_DATA_SPLIT = 0.7\n",
        "VALIDATION_DATA_SPLIT = 0.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teIYgE3l5wvI"
      },
      "source": [
        "## Pre-Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjSsXDJk6-G0"
      },
      "source": [
        "### Unzipping the email data\n",
        "\n",
        "First, the emails have to be unzipped. This creates two directories, `emails/ham` and `emails/spam`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Vh9cy3jb6qx6"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"emails.zip\", \"r\") as zf:\n",
        "  zf.extractall(\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAsO_PIm64PX"
      },
      "source": [
        "### Reading the data from file\n",
        "\n",
        "The next step is to read the text from the email files, so the format of the files needs to be understood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF8oyQYR5wvI"
      },
      "source": [
        "A `formatString()` function is defined as a helper to format the strings that are read from the files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CHIKgZlT5wvI"
      },
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Function to format email strings\n",
        "###########################################################\n",
        "def formatString(str):\n",
        "\n",
        "\t# Remove special characters\n",
        "\tnewstr = re.sub(\"[^a-zA-Z0-9 ]+\", \" \", str)\n",
        "\n",
        "\t# Remove newlines\n",
        "\tnewstr = re.sub(\"\\\\r\\\\n\", \" \", newstr)\n",
        "\n",
        "\t# Remove repeated spaces\n",
        "\tnewstr = re.sub(\" +\", \" \", newstr)\n",
        "\n",
        "\t# Remove leading and trailing spaces\n",
        "\tnewstr = newstr.strip()\n",
        "\t\n",
        "\treturn newstr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBl4VFic5wvI"
      },
      "source": [
        "Next, a `getEmailTextFromFile()` function is defined that  actually reads the data from the email text files.  In this function, the subject and body text are extracted individually, ignoring the remainder of the email headers that are present in the files.\n",
        "\n",
        "I did consider including the headers as features, but in the end decided that they probably wouldn't have as much influence over the classification as the subject and body of the emails. Some experimentation along those lines might be interesting.\n",
        "\n",
        "As part of this read process, extraneous characters are removed from the text. Some files also turned out to be encoded in ANSI rather than UTF-8, so that situation is handled here too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DAlFvNE75wvI"
      },
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Read email text from file\n",
        "###########################################################\n",
        "def getEmailTextFromFile(filename):\n",
        "\n",
        "\temailText = \"\"\n",
        "\tsubject = \"\"\n",
        "\tbody = \"\"\n",
        "\n",
        "\t# Open the file\n",
        "\ttry:\n",
        "\n",
        "\t\t# Read using UTF-8 encoding\n",
        "\t\twith open(filename, \"r\", encoding=\"utf-8\") as emailFile:\n",
        "\t\t\temailText = emailFile.read()\n",
        "\n",
        "\texcept UnicodeDecodeError:\n",
        "\n",
        "\t\t# Some files are encoded differently\n",
        "\t\twith open(filename, \"r\", encoding=\"latin-1\") as emailFile:\n",
        "\t\t\temailText = emailFile.read()\n",
        "\n",
        "\t# Extract the subject\n",
        "\tsubjectStart = emailText.find(\"Subject: \") + 9\n",
        "\tsubject = emailText[subjectStart : emailText.find(\"\\n\", subjectStart) ]\n",
        "\n",
        "\t# Extract the body\n",
        "\tbody = emailText[emailText.find(\"\\n\\n\") + 1 :]\n",
        "\n",
        "\t# Format the strings\n",
        "\tsubject = formatString(subject)\n",
        "\tbody = formatString(body)\n",
        "\n",
        "\treturn subject, body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAowM3El5wvJ"
      },
      "source": [
        "Next, the emails are ingested and parsed. The output is `allEmails` a list of dictionary email objects with the following structure:\n",
        "\n",
        "|Field|Meaning|\n",
        "|---|---|\n",
        "|subject|Text from the email's subject line|\n",
        "|body|Text from the email's body|\n",
        "|type|The email's class, i.e. \"ham\" or \"spam\"|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25sl4DNS5wvJ",
        "outputId": "83e30fd6-fa6e-4312-926f-193c62398c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2551 ham files\n",
            "There are 501 spam files\n",
            "Ingested 3052 total email files\n"
          ]
        }
      ],
      "source": [
        "# Initialize emails list\n",
        "allEmails = []\n",
        "\n",
        "# Initialize label classes\n",
        "uniqueLabels = [\"Ham\", \"Spam\"]\n",
        "\n",
        "# Formulate email directory paths\n",
        "hamDir = os.path.join(BASE_EMAILS_DIR, \"ham\")\n",
        "spamDir = os.path.join(BASE_EMAILS_DIR, \"spam\")\n",
        "\n",
        "# Get email filenames\n",
        "hamFilenames = os.listdir(hamDir)\n",
        "spamFilenames = os.listdir(spamDir)\n",
        "\n",
        "# Display the number of emails in each directory\n",
        "print(\"There are %i ham files\" % len(hamFilenames))\n",
        "print(\"There are %i spam files\" % len(spamFilenames))\n",
        "\n",
        "# Read ham emails\n",
        "for filename in hamFilenames:\n",
        "\n",
        "\t# Formulate email filename\n",
        "\tfilename = os.path.join(hamDir, filename)\n",
        "\n",
        "\t# Read the subject and body from the file\n",
        "\tsubject, body = getEmailTextFromFile(filename)\n",
        "\t\n",
        "\t# Create the email object\n",
        "\temail = { \"subject\": subject, \"body\": body, \"type\": \"Ham\" }\n",
        "\n",
        "\t# Add email to collection\n",
        "\tallEmails.append(email)\n",
        "\n",
        "# Read spam emails\n",
        "for filename in spamFilenames:\n",
        "\n",
        "\t# Formulate email filename\n",
        "\tfilename = os.path.join(spamDir, filename)\n",
        "\n",
        "\t# Read the subject and body from the file\n",
        "\tsubject, body = getEmailTextFromFile(filename)\n",
        "\t\n",
        "\t# Create the email object\n",
        "\temail = { \"subject\": subject, \"body\": body, \"type\": \"Spam\" }\n",
        "\n",
        "\t# Add email to collection\n",
        "\tallEmails.append(email)\n",
        "\n",
        "print(\"Ingested\", len(allEmails), \"total email files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhb9sAoE5wvJ"
      },
      "source": [
        "### Data Cleaning and Normalization\n",
        "\n",
        "Next, I need a function to clean and normalize the data in preparation for splitting into training, validation and test sets.\n",
        "\n",
        "### Randomization  \n",
        "As a first step, the dataset is shuffled to randomize the order of the emails. This helps to ensure that there isn't any adverse influence if the emails are clustered or grouped in some way.  \n",
        "\n",
        "### Cleaning  \n",
        "To simplify the data and help to improve accuracy, the following actions are performed:\n",
        "\n",
        "- The email subject is merged with the email body\n",
        "- Stopwords are removed\n",
        "- All words are lemmatized where necessary\n",
        "- Unusually long words are removed\n",
        "\n",
        "The subject and body text are assumed to be equally relevant to classifying the emails, and so they are merged into a single block of text for the purposes of analysis.\n",
        "\n",
        "#### Stopwords  \n",
        "Stopwords are filtered out of the email data using the list of stopwords from the NLTK library. These words don't  offer much lexical significance, so removing them helps with accuracy.\n",
        "\n",
        "#### Lemmatization  \n",
        "Since the text contains many different derivations of words, lemmatization is necessary in order to reduce the multitude of forms down to a common root word. This helps to improve the accuracy of the model.\n",
        "\n",
        "#### Long Words  \n",
        "While it is possible to have extremely long English words that exceed the threshold that I've chosen here, in practice it's unlikely to be the case, and so they're removed here. This has the side benefit of removing some long nonsense strings that are present in spam emails.  \n",
        "\n",
        "The threshold of 20 letters was chosen based on the length of the longest English words likely to be encountered in common usage, as suggested in Making the Alphabet Dance (Eckler, 1996)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6JiZYJKK5wvJ"
      },
      "outputs": [],
      "source": [
        "# Using the WordNet lemmatizer\n",
        "wordLemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJmD3olcADWQ",
        "outputId": "4faf1387-1ea7-48c9-9512-8eff6e88bc05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to D:\\Projects\\UoL\\Natural\n",
            "[nltk_data]     Language Processing\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to D:\\Projects\\UoL\\Natural\n",
            "[nltk_data]     Language Processing\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to D:\\Projects\\UoL\\Natural\n",
            "[nltk_data]     Language Processing\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download some NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "K-ukMMZA5wvK"
      },
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Process the email data\n",
        "#\n",
        "# - Returns:\n",
        "#     emailData: list of combined email subject and body\n",
        "#     labelData: list of labels associated with emails\n",
        "###########################################################\n",
        "def processEmails(emails):\n",
        "\n",
        "\t# Define the email and label datasets\n",
        "\temailData = []\n",
        "\tlabelData = []\n",
        "\n",
        "\t# Shuffle the emails\n",
        "\tshuffledEmails = emails.copy()\n",
        "\trandom.shuffle(shuffledEmails)\n",
        "\n",
        "\t# Process each email\n",
        "\tfor email in shuffledEmails:\n",
        "\n",
        "\t\t# Merge the email subject and body text\n",
        "\t\temailText = email[\"subject\"] + \" \" + email[\"body\"]\n",
        "\n",
        "\t\t# Make the text lowercase\n",
        "\t\temailText = emailText.lower()\n",
        "\n",
        "\t\t# Tokenize and remove stopwords\n",
        "\t\temailWordTokens = nltk.word_tokenize(emailText)\n",
        "\t\temailText = [word for word in emailWordTokens if not word in stopwords.words(\"english\")]\n",
        "\n",
        "\t\t# Remove words that are too long to be actual words\n",
        "\t\temailText = [word for word in emailText if len(word) < MAX_WORD_LEN]\n",
        "\n",
        "\t\t# Apply lemmatizer\n",
        "\t\temailText = [wordLemmatizer.lemmatize(word) for word in emailText]\n",
        "\n",
        "\t\t# Convert back to space delimited sentence\n",
        "\t\temailText = \" \".join(emailText)\n",
        "\n",
        "\t\t# Add the remaining words to the dataset\n",
        "\t\temailData.append(emailText)\n",
        "\n",
        "\t\t# Extract the label for each email\n",
        "\t\tlabelData.append(email[\"type\"])\n",
        "\n",
        "\t# Return the emails and labels\n",
        "\treturn emailData, labelData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "g3VJ6NQP5wvK"
      },
      "outputs": [],
      "source": [
        "# Process the emails that were read from the file\n",
        "emailData, labelData = processEmails(allEmails)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5jCJfN75wvK"
      },
      "source": [
        "It's a good idea to check a random sampling of the ingested emails to make sure that everything has worked fine so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a-9vGju5wvK",
        "outputId": "c3df0295-ffa9-4bfa-b93b-38dfaf66088d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined subject and body for email #314:\n",
            " 'slaughter name god j justin mason jm jmason org writes j tibetan buddhism btw seem like awfully j ni...'\n",
            " This email is classified as: Ham\n",
            "\n",
            "Combined subject and body for email #1723:\n",
            " 'uk leading pc specialist nationwide pc repair upgrade call charge hourly charge picked home returned...'\n",
            " This email is classified as: Spam\n",
            "\n",
            "Combined subject and body for email #2479:\n",
            " 'ilug stop mlm insanity greeting receiving letter expressed interest receiving information online bus...'\n",
            " This email is classified as: Spam\n",
            "\n",
            "Combined subject and body for email #1145:\n",
            " 'recommended viewing g geege schuman geege barrera org writes g sure neurochemical process initiated ...'\n",
            " This email is classified as: Ham\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display text and labels for some random emails\n",
        "for i in range(4):\n",
        "\tsampleIndex = random.randint(0, len(emailData))\n",
        "\tnumSampleChars = 100\n",
        "\tprint(\"Combined subject and body for email #%i:\\n '%s...'\" % (sampleIndex, emailData[sampleIndex][:numSampleChars]))\n",
        "\tprint(\" This email is classified as: %s\" % labelData[sampleIndex])\n",
        "\tprint(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwWEBPA55wvK"
      },
      "source": [
        "It's also important to check the distribution of the labels in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "561TjacX5wvK",
        "outputId": "cb6fd0a3-d2ac-41cf-f6da-45503d0f921c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The label distribution over the entire dataset is:\n",
            "  Ham: 83.6%\n",
            "  Spam: 16.4%\n"
          ]
        }
      ],
      "source": [
        "# Check for the distribution of the labels\n",
        "labelDist = np.asarray(labelData)\n",
        "allLabelDists = np.unique(labelDist, return_counts=True)\n",
        "numItems = len(labelData)\n",
        "\n",
        "# Print distribution ratio\n",
        "print(\"The label distribution over the entire dataset is:\")\n",
        "print(\"  Ham: %.1f%%\" % (allLabelDists[1][0] / numItems * 100))\n",
        "print(\"  Spam: %.1f%%\" % (allLabelDists[1][1] / numItems * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGY_zi5V5wvK"
      },
      "source": [
        "There are approximately five times more legitimate emails than spam ones, so the dataset is clearly not a balanced one.\n",
        "\n",
        "I don't address the imbalance in this test, but there are data augmentation techniques that can address imbalanced classes like this, e.g. thesaurus, back translation, etc.\n",
        "\n",
        "A severe imbalance has the potential to skew the model's accuracy, but I decided to go ahead with the current distribution and see how well it fared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P77Mopy5wvL"
      },
      "source": [
        "### Split the Data\n",
        "\n",
        "OK so next the data is split into __training__, __validation__ and __test__ sets.\n",
        "\n",
        "- The __training__ set is used to train the predictive model.\n",
        "- The __validation__ is used to optimize the model during training.\n",
        "- The __test__ set is used to evaluate the accuracy of the trained model's predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2P_0ZlS5wvL",
        "outputId": "1040b221-614e-44c8-e567-5863d9780bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 3052 total emails\n",
            "- There are 2136 items in the training set\n",
            "- There are 457 items in the validation set\n",
            "- There are 459 items in the test set\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "\n",
        "# Calculate the size of the training set\n",
        "numItems = len(emailData)\n",
        "trainingSplitIndex = int(numItems * TRAIN_DATA_SPLIT)\n",
        "validationSplitIndex = int(numItems * VALIDATION_DATA_SPLIT) + trainingSplitIndex\n",
        "\n",
        "# Split training data\n",
        "trainingData = emailData[:trainingSplitIndex]\n",
        "trainingLabels = labelData[:trainingSplitIndex]\n",
        "\n",
        "# Split validation data\n",
        "validationData = emailData[trainingSplitIndex : validationSplitIndex]\n",
        "validationLabels = labelData[trainingSplitIndex : validationSplitIndex]\n",
        "\n",
        "# Split test data\n",
        "testData = emailData[validationSplitIndex:]\n",
        "testLabels = labelData[validationSplitIndex:]\n",
        "\n",
        "# Display sizes\n",
        "print(\"There are %i total emails\" % numItems)\n",
        "print(\"- There are %i items in the training set\" % len(trainingData))\n",
        "print(\"- There are %i items in the validation set\" % len(validationData))\n",
        "print(\"- There are %i items in the test set\" % (len(testData)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA29UNHC5wvL"
      },
      "source": [
        "Since the random shuffling may result in a different ratio of ham/spam content in the individual training, validation and test datasets, it's best to examine the distribution in each individual set too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5azXI8dc5wvL",
        "outputId": "de0f460a-0b29-4076-b477-1c09881ed813"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ham</th>\n",
              "      <th>Spam</th>\n",
              "      <th>Spam %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Training</th>\n",
              "      <td>1794</td>\n",
              "      <td>342</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Validation</th>\n",
              "      <td>376</td>\n",
              "      <td>81</td>\n",
              "      <td>17.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>381</td>\n",
              "      <td>78</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Ham  Spam  Spam %\n",
              "Training    1794   342    16.0\n",
              "Validation   376    81    17.7\n",
              "Test         381    78    17.0"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summarize the label counts\n",
        "trainingCounts = pd.DataFrame(trainingLabels, columns=[\"Training\"]).groupby(\"Training\").size()\n",
        "validationCounts = pd.DataFrame(validationLabels, columns=[\"Validation\"]).groupby(\"Validation\").size()\n",
        "testCounts = pd.DataFrame(testLabels, columns=[\"Test\"]).groupby(\"Test\").size()\n",
        "\n",
        "# Merge the sets of counts together\n",
        "labelDists = pd.concat([trainingCounts, validationCounts, testCounts], axis=1).transpose()\n",
        "labelDists.rename(index={ 0: \"Training\", 1: \"Validation\", 2: \"Test\"}, inplace=True)\n",
        "\n",
        "# Calculate the ham/spam ratio\n",
        "labelDists[\"Spam %\"] = round(labelDists[\"Spam\"] / (labelDists[\"Ham\"] + labelDists[\"Spam\"]) * 100, 1)\n",
        "\n",
        "labelDists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wZEyQCi5wvL"
      },
      "source": [
        "In this run, at least, the variance of the ham-to-spam ratio in each individual set isn't large enough to be of concern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e3eu_Yd5wvL"
      },
      "source": [
        "### Vocabulary\n",
        "\n",
        "Counting the number of unique words defines the size of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68tGWL4o5wvL",
        "outputId": "0dd2f1a2-7e6c-4741-f4c6-a97dbcf0ff4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data has 34753 unique words\n"
          ]
        }
      ],
      "source": [
        "# Determine the size of the vocabulary\n",
        "# This will be based on the size of the training data only, since in theory \n",
        "# the model will have never seen either the validation or test data.\n",
        "tempVocab = { \"\" }\n",
        "for email in trainingData:\n",
        "\tfor word in email.split(\" \"):\n",
        "\t\ttempVocab.add(word)\n",
        "print(\"Training data has %i unique words\" % len(tempVocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKhl6wSL5wvL"
      },
      "source": [
        "### Vectorize the Data\n",
        "\n",
        "The model requires that the email text data be vectorized, or converted to numerical vector embeddings, prior to being used for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBO5XP5s5wvL",
        "outputId": "c4c241ae-081e-44f2-a9f6-4c46a5f7b89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 3052 total emails\n",
            "- There are 2136 items in the vectorized training set (non-vectorized 2136)\n",
            "- There are 457 items in the vectorized validation set (non-vectorized 457)\n",
            "- There are 459 items in the vectorized test set (non-vectorized 459)\n"
          ]
        }
      ],
      "source": [
        "# Set the maximum vocabulary size\n",
        "MAX_VOCAB_SIZE = len(tempVocab)\n",
        "\n",
        "# Instantiate vectorizer\n",
        "vectorizer = tf.keras.layers.TextVectorization(max_tokens=MAX_VOCAB_SIZE)\n",
        "\n",
        "# Adapt to the input text\n",
        "vectorizer.adapt(emailData)\n",
        "vectorizedEmailData = vectorizer(emailData)\n",
        "\n",
        "# Split the vectorized input data\n",
        "vectorizedTrainingData = vectorizedEmailData[:trainingSplitIndex]\n",
        "vectorizedValidationData = vectorizedEmailData[trainingSplitIndex : validationSplitIndex]\n",
        "vectorizedTestData = vectorizedEmailData[validationSplitIndex:]\n",
        "\n",
        "# Get the maximum number of tokens for each email in the dataset\n",
        "# This is used later to configure the embedding layer's dimensions\n",
        "maxlen=len(vectorizedTrainingData[0])\n",
        "\n",
        "# Display the sizes of the datasets for verification.\n",
        "# They should match the non-vectorized dataset sizes.\n",
        "print(\"There are %i total emails\" % numItems)\n",
        "print(\"- There are %i items in the vectorized training set (non-vectorized %i)\" % (len(vectorizedTrainingData), len(trainingData)))\n",
        "print(\"- There are %i items in the vectorized validation set (non-vectorized %i)\" % (len(vectorizedValidationData), len(validationData)))\n",
        "print(\"- There are %i items in the vectorized test set (non-vectorized %i)\" % (len(vectorizedTestData), len(testData)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2OvXyVr5wvM"
      },
      "source": [
        "A similar conversion is applied to the training and validation labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Ycb6Zj2X5wvM"
      },
      "outputs": [],
      "source": [
        "# We'll also need to convert the binary labels to floats\n",
        "encodedTrainingLabels = np.asarray([1.0 if label == \"Ham\" else 0.0 for label in trainingLabels])\n",
        "encodedValidationLabels = np.asarray([1.0 if label == \"Ham\" else 0.0 for label in validationLabels])\n",
        "encodedTestLabels = np.asarray([1.0 if label == \"Ham\" else 0.0 for label in testLabels])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAX3cWUe5wvM"
      },
      "source": [
        "### Create the Transformer  \n",
        "Next the Transformer model is constructed. As mentioned previously this is a Transformer model using word embeddings and Multi-Head Attention, as described in the Google paper _Attention Is All You Need_ (Vaswani, et al., 2017).  \n",
        "\n",
        "I dervied the practical implementation details from the Keras code examples page [Text Classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/) (Nandan, 2020), but I've added explanatory comments and expanded variable names for clarity.\n",
        "\n",
        "The Transformer block is implemented as a separate layer class added to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Y2gGVfjQ5wvM"
      },
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Transformer layer\n",
        "###########################################################\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        # Define Multi-Head Attention layer\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "        # Define dense layers\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
        "        )\n",
        "\n",
        "        # Define normalization layers\n",
        "        self.normalizedLayer1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normalizedLayer2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Define dropout layers\n",
        "        self.dropoutLayer1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropoutLayer2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    # Class instance can be called like a function\n",
        "    def call(self, inputs, training):\n",
        "\n",
        "        # Process Multi-Head Attention layer\n",
        "        attentionLayerOutput = self.att(inputs, inputs)\n",
        "        attentionLayerOutput = self.dropoutLayer1(attentionLayerOutput, training=training)\n",
        "\n",
        "        # Apply layer normalization\n",
        "        outputLayer1 = self.normalizedLayer1(inputs + attentionLayerOutput)\n",
        "\n",
        "        # Process the feed forward dense layer\n",
        "        denseLayerOutput = self.ffn(outputLayer1)\n",
        "        denseLayerOutput = self.dropoutLayer2(denseLayerOutput, training=training)\n",
        "        \n",
        "        return self.normalizedLayer2(outputLayer1 + denseLayerOutput)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObkaRHTA5wvM"
      },
      "source": [
        "Unlike recurrent models such as RNN and LSTM which reference only recently seen data in the sequence, the Transformer model requires both embedded tokens as well as the position of the tokens in the text data.\n",
        "\n",
        "This requires two separate embedding layers for these purposes, one for tokens and one for the position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JJitPHut5wvM"
      },
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Token Layer and Position Layer\n",
        "###########################################################\n",
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "\n",
        "        # Initialize token layer\n",
        "        self.tokenEmbeddings = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "\n",
        "        # Initialize position layer\n",
        "        self.positionalEmbeddings = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    # Class instance can be called like a function\n",
        "    def call(self, x):\n",
        "\n",
        "        # Embed the position\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        tokenPositions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        tokenPositions = self.positionalEmbeddings(tokenPositions)\n",
        "\n",
        "        # Embed the token\n",
        "        x = self.tokenEmbeddings(x)\n",
        "\n",
        "        # Return the positional embeddings\n",
        "        return x + tokenPositions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFJK00IQ5wvM"
      },
      "source": [
        "Next the various layers are assembled to produce the complete Transformer model. This series of steps is likewise derived from _Text Classification with Transformer_ (Nandan, 2020), with variable names expanded for clarity.  \n",
        "\n",
        "Unlike that example, however, the output layer in this implementation is reduced to one node and its activation function changed from `softmax` to `sigmoid`, in order to perform binary classification rather than multi-class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YF-xD1Ux5wvM"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "EMBEDDING_DIM = 64  # Embedding size for each token\n",
        "NUM_ATTENTION_HEADS = 2  # Number of attention heads\n",
        "HIDDEN_LAYER_SIZE = 64  # Size of the Transformer's hidden layer\n",
        "DROPOUT_RATE = 0.1 # Dropout layer rate\n",
        "\n",
        "# Start with the input layer\n",
        "inputs = tf.keras.layers.Input(shape=(maxlen,))\n",
        "\n",
        "# Add the embedding layer\n",
        "embeddingLayer = TokenAndPositionEmbedding(maxlen, MAX_VOCAB_SIZE, EMBEDDING_DIM)\n",
        "modelLayer = embeddingLayer(inputs)\n",
        "\n",
        "# Add the transformer block\n",
        "transformerBlock = TransformerBlock(EMBEDDING_DIM, NUM_ATTENTION_HEADS, HIDDEN_LAYER_SIZE)\n",
        "modelLayer = transformerBlock(modelLayer)\n",
        "\n",
        "# Pooling layer\n",
        "modelLayer = tf.keras.layers.GlobalAveragePooling1D()(modelLayer)\n",
        "modelLayer = tf.keras.layers.Dropout(DROPOUT_RATE)(modelLayer)\n",
        "\n",
        "# Dense layers\n",
        "modelLayer = tf.keras.layers.Dense(20, activation=\"relu\")(modelLayer)\n",
        "modelLayer = tf.keras.layers.Dropout(DROPOUT_RATE)(modelLayer)\n",
        "\n",
        "# Output layer\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(modelLayer)\n",
        "\n",
        "# Assemble the Transformer model\n",
        "xfModel = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb_rWaJz5wvM"
      },
      "source": [
        "### Tuning and Compilation\n",
        "\n",
        "To tune the performance of the model, the hyperparameters are adjusted over several training iterations.  \n",
        "\n",
        "Specifically, the dimensions of the hidden layers and embedding sizes are each adjusted, with successive experiments resulting in small incremental improvements (around 1%) to the model's accuracy against the previously unseen data. Depending on hardware, training for each iteration can take quite some time.  \n",
        "\n",
        "The model is compiled and a summary of the layers is displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psYhe8gE5wvN",
        "outputId": "6d2aec1d-d2ab-467d-b624-0df21a0312b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 7635)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 7635, 64)         2712832   \n",
            " g_1 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_block_1 (Transf  (None, 7635, 64)         41792     \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                1300      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,755,945\n",
            "Trainable params: 2,755,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "xfModel.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "xfModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiKAqagI5wvN"
      },
      "source": [
        "An `EarlyStopping` callback class is defined to end the training early if the model stops improving over a defined (patience) number of epochs, i.e. to stop training if the validation loss is clearly not getting better over time.  \n",
        "\n",
        "This is necessary since it's initially unclear how many epochs it would take for the validation loss to converge to a minimum, and once attained it would just be a waste of time to continue training epochs that don't return any significant improvement.  \n",
        "\n",
        "The callback class provides another great benefit: the best model weights are retained if the training does end early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "I55sHKWy5wvN"
      },
      "outputs": [],
      "source": [
        "# Define the EarlyStopping callback\n",
        "xfModelCallback = tf.keras.callbacks.EarlyStopping(\n",
        "\tmonitor=\"val_loss\", \n",
        "\tpatience=3, \n",
        "\trestore_best_weights=True,\n",
        "\tverbose=1\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt-jGf-35wvN"
      },
      "source": [
        "## Train the Transformer Model  \n",
        "The Transformer model is then trained using the vectorized data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2WepTMX5wvN",
        "outputId": "7d1a0a75-1ae0-4d56-82de-80f56607547f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "214/214 [==============================] - 1919s 9s/step - loss: 0.4377 - accuracy: 0.8347 - val_loss: 0.4011 - val_accuracy: 0.8293\n",
            "Epoch 2/50\n",
            "214/214 [==============================] - 1918s 9s/step - loss: 0.1804 - accuracy: 0.9377 - val_loss: 0.0833 - val_accuracy: 0.9694\n",
            "Epoch 3/50\n",
            "214/214 [==============================] - 1918s 9s/step - loss: 0.0638 - accuracy: 0.9817 - val_loss: 0.0936 - val_accuracy: 0.9519\n",
            "Epoch 4/50\n",
            "214/214 [==============================] - 1963s 9s/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
            "Epoch 5/50\n",
            "214/214 [==============================] - 1969s 9s/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
            "Epoch 6/50\n",
            "214/214 [==============================] - 1968s 9s/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0800 - val_accuracy: 0.9759\n",
            "Epoch 7/50\n",
            "214/214 [==============================] - 1967s 9s/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0709 - val_accuracy: 0.9781\n",
            "Epoch 8/50\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986Restoring model weights from the end of the best epoch: 5.\n",
            "214/214 [==============================] - 1956s 9s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0721 - val_accuracy: 0.9803\n",
            "Epoch 8: early stopping\n",
            "Model training complete!\n",
            "\n",
            "Elapsed training time: 15577.1s (259.6 minutes)\n"
          ]
        }
      ],
      "source": [
        "# Number of epoch cycles to train\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# Number of items to batch per epoch. Lower this if you encounter out of memory (OOM) issues\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Record start time\n",
        "startTimeXf = time.time()\n",
        "\n",
        "# Train the model\n",
        "historyXf = xfModel.fit(\n",
        "\tvectorizedTrainingData, \n",
        "\tencodedTrainingLabels, \n",
        "\tbatch_size=BATCH_SIZE, \n",
        "\tepochs=NUM_EPOCHS, \n",
        "\tvalidation_data=(vectorizedValidationData, encodedValidationLabels),\n",
        "\tcallbacks=[xfModelCallback])\n",
        "\n",
        "print(\"Model training complete!\\n\")\n",
        "\n",
        "# Display elapsed time\n",
        "endTimeXf = time.time()\n",
        "elapsedTimeXf = endTimeXf - startTimeXf\n",
        "print(\"Elapsed training time: %.1fs (%.1f minutes)\" % (elapsedTimeXf, elapsedTimeXf/60))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-iOUURAm5wvN"
      },
      "source": [
        "Training on an AMD Ryzen 9 5900X 12-Core CPU and an NVIDIA GeForce RTX 2060 SUPER took almost 4.5 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3znQapo5wvN"
      },
      "source": [
        "### Chart the Training Accuracy  \n",
        "\n",
        "Once the model has been trained, the accuracy and loss across the training epochs can be charted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "Vx256ic_5wvN",
        "outputId": "187dbaab-ad9f-49d0-b196-9101b6f7d5ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "# Plot the accuracy and loss history\n",
        "plot_graphs(historyXf, 'accuracy')\n",
        "plot_graphs(historyXf, 'loss')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HIPtgDFB5wvN"
      },
      "source": [
        "The validation accuracy closely follows the same trend as the training data, flattening out over time. This demonstrates a very slight loss of accuracy vs the training data, which is to be expected.\n",
        "\n",
        "Similarly, the validation loss closely parallels the training loss, reaching optimum performance at epoch 5 (Note: the epochs are zero-indexed on the chart, so epoch 4 on the chart)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pAh27C7WXrQL"
      },
      "source": [
        "### Save the trained model\n",
        "\n",
        "I saved the trained model weights in case I wanted to play around with predictions later, without having to go through the whole training process all over again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The saved model name\n",
        "modelName = \"xf_spam_classifier\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6sNIxwG0Xp2o",
        "outputId": "8be08f4f-7c84-40ab-e538-abdc494ba0b3"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "xfModel.save(\"./\" + modelName)\n",
        "\n",
        "# Archive the model folder\n",
        "shutil.make_archive(modelName, \"zip\", modelName)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The loading function is only used if I'm resuming from another session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "def load_saved_model(modelName):\n",
        "\n",
        "  # Unzip the trained model \n",
        "  with zipfile.ZipFile(\"./\" + modelName + \".zip\", \"r\") as zf:\n",
        "    zf.extractall(\"./\" + modelName)\n",
        "  \n",
        "  return tf.keras.models.load_model(modelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load saved model if resuming\n",
        "#xfModel = load_saved_model(modelName)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_8Njgi5wvO"
      },
      "source": [
        "### Calculate the Model's Scores\n",
        "\n",
        "Now to calculate the model's performance metrics.\n",
        "\n",
        "As a first step, a set of label predictions is made against the previously unseen email data contained in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "huPKdyvA5wvO",
        "outputId": "30399de3-8b6b-4375-9f19-3ebd2b80d3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 734s 26s/step\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions using the Transformer\n",
        "xfPredictedLabels = xfModel.predict(vectorizedTestData)\n",
        "\n",
        "# Convert probabilistic values to text labels\n",
        "xfPredictedLabels = [\"Ham\" if label >= 0.5 else \"Spam\" for label in xfPredictedLabels]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mFr9dj7s5wvO"
      },
      "source": [
        "These predictions are then compared against the actual labels to calculate the various performance scores.\n",
        "\n",
        "This is a function to calculate the most common scores, namely accuracy, precision, recall and F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "###########################################################\n",
        "# Calculate model scores\n",
        "###########################################################\n",
        "def calculateModelScores(actualLabels, predictedLabels):\n",
        "\n",
        "\t# Calculate the scores\n",
        "\taccuracyScore = accuracy_score(actualLabels, predictedLabels)\n",
        "\tprecisionScore = precision_score(actualLabels, predictedLabels, pos_label=\"Ham\", average=\"binary\")\n",
        "\trecallScore = recall_score(actualLabels, predictedLabels, pos_label=\"Ham\", average=\"binary\")\n",
        "\tf1Score = f1_score(actualLabels, predictedLabels, pos_label=\"Ham\", average=\"binary\")\n",
        "\n",
        "\treturn accuracyScore, precisionScore, recallScore, f1Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "s_Bs08mA5wvO"
      },
      "outputs": [],
      "source": [
        "# Calculate the scores for the target model\n",
        "xfAccuracy, xfPrecision, xfRecall, xfF1 = calculateModelScores(testLabels, xfPredictedLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KzEr8wYu5wvO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.99\n",
            "Model Precision: 0.99\n",
            "Model Recall: 0.99\n",
            "Model F1: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Display the model scores\n",
        "print(\"Model Accuracy:\", round(xfAccuracy, 2))\n",
        "print(\"Model Precision:\", round(xfPrecision, 2))\n",
        "print(\"Model Recall:\", round(xfRecall, 2))\n",
        "print(\"Model F1:\", round(xfF1, 2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are excellent scores, but even if there was more variation in the metrics, the F1 score would be particularly relevant here due to the imbalance in the data set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt5aTKt-5wvO"
      },
      "source": [
        "### Analyze Errors\n",
        "\n",
        "We can also use the results to analyze the nature of the prediction errors using a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "yzDg_f6D5wvO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model achieved an accuracy of 98.9%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(91.68, 0.5, 'Predicted Labels')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the accuracy\n",
        "print(\"The model achieved an accuracy of %.1f%%\" % (xfAccuracy * 100))\n",
        "\n",
        "# Generate the confusion matrix\n",
        "xfConfusionMatrix = confusion_matrix(testLabels, xfPredictedLabels)\n",
        "\n",
        "# Extract the matrix componenets\n",
        "xfTN, xfFP, xfFN, xfTP = xfConfusionMatrix.ravel()\n",
        "\n",
        "# Visualize the performance\n",
        "sns.heatmap(xfConfusionMatrix.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=uniqueLabels, yticklabels=uniqueLabels)\n",
        "plt.xlabel(\"Actual Labels\")\n",
        "plt.ylabel(\"Predicted Labels\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T3xZNsKz5wvO"
      },
      "source": [
        "From the confusion matrix, it's obvious that the model made very few prediction errors overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "MQ4KtNZr5wvO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy was 0.99\n",
            "- This indicates how often the model makes correct predictions.\n",
            "\n",
            "The precision was 0.99\n",
            "- This is a measure of the model's ability to avoid classifying a spam email as legitimate.\n",
            "\n",
            "The recall was 0.99\n",
            "- This is a measure of the model's ability to detect legitimate emails.\n",
            "\n",
            "The F1 score was 0.99\n",
            "- This is another measure of the model's accuracy. It can be more reliable in situations where the dataset is imbalanced.\n",
            "\n",
            "There were 2 false positives and 3 false negatives.\n",
            "\n",
            "Model was mistaken in 1.1% of cases.\n"
          ]
        }
      ],
      "source": [
        "# Display model statistics and error rates\n",
        "print(\"The accuracy was %.2f\" % xfAccuracy)\n",
        "print(\"- This indicates how often the model makes correct predictions.\\n\")\n",
        "\n",
        "print(\"The precision was %.2f\" % xfPrecision)\n",
        "print(\"- This is a measure of the model's ability to avoid classifying a spam email as legitimate.\\n\")\n",
        "\n",
        "print(\"The recall was %.2f\" % xfRecall)\n",
        "print(\"- This is a measure of the model's ability to detect legitimate emails.\\n\")\n",
        "\n",
        "print(\"The F1 score was %.2f\" % xfF1)\n",
        "print(\"- This is another measure of the model's accuracy. It can be more reliable in situations where the dataset is imbalanced.\\n\")\n",
        "\n",
        "print(\"There were %i false positives and %i false negatives.\\n\" % (xfFP, xfFN))\n",
        "\n",
        "xfMistaken = (xfFP + xfFN) / len(testData) * 100\n",
        "print(\"Model was mistaken in %.1f%% of cases.\" % xfMistaken)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "As1Eov4s5wvP"
      },
      "source": [
        "An excellent result! The model was only mistaken __1.1%__ of the time against the test dataset. In other words, this model correctly classified 99 out of every 100 emails based on predictions against previously unseen data.\n",
        "\n",
        "This margin of error could possibly be further improved by additional tuning of the hyperparameters, or possibly applying data augmentation to the class imbalance disparity noted earlier."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHKhnfF5wvP"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "When applied towards the task of classifying previously unseen ham and spam emails, the Transformer model appears to perform exceptionally well. It requires a significant amount of time for training vs a simpler model--such as Multinomial Naive Bayes for example--but its particular characteristics and Multi-Head Attention mechanism allowed for very effective discrimination between samples.  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "TF",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a619d752d17746df1f1953f3d051b3a3e10a0a0c0bcace8f8e346299d17ff55d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
